{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyCon2020_Scraping_Basics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZy-RvQX6l-3",
        "colab_type": "text"
      },
      "source": [
        "<center>\n",
        " <img src=\"https://drive.google.com/uc?export=view&id=1JpQLPJGs44Tu1Z-xujVGKDyb6ikSwlCl\"  alt=\"PyCon header\" height=\"150\"/>\n",
        "\n",
        "<br>\n",
        "<h1>\n",
        "<TT>It's Officially Legal so Let's Scrape the Web</TT>\n",
        "</h1>\n",
        "Kimberly Fessel  &nbsp &#8226 &nbsp\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1aMmmYHcHkwRFcUw5v_HD3i0Kt5sGH7Gq\"  alt=\"Twitter logo\" height=\"20\"/> @kimberlyfessel &nbsp &#8226 &nbsp\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1s8InMOalYkxWyMeu1vhG5LyF1Jc9wczH\"  alt=\"LinkedIn logo\" height=\"20\"/> &nbsp kimberlyfessel\n",
        "<br> <br>\n",
        "<h2> <TT> Scraping Basics </TT> </h2>\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGhoHtzhIj5k",
        "colab_type": "text"
      },
      "source": [
        "#Introduction to Google Colab and `BeautifulSoup`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW6O_39pSlfP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1o6M5j-41qjCA85qgETgG0fJooZw6HXFZ\"  alt=\"BeautifulSoup logo\" height=\"100\"/>\n",
        "\n",
        "- Executes Python code on the fly\n",
        "- Interactivity allows for instant feedback\n",
        "- Memory persists across cells\n",
        "- `shift+enter` \n",
        "- Use [markdown](https://blog.ghost.org/markdown/) (TEXT) mode for adding text like this\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1cY9SICwwAbrNmuhTha3ilBl330jDie51\"  alt=\"BeautifulSoup logo\" height=\"100\"/>\n",
        "\n",
        "- open-source Python library\n",
        "- extract data from HTML files\n",
        "- understands HTML structure by working with a [parser](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser) (`lxml`, `html5lib`, etc.) \n",
        "- [BeautifulSoup documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) for reference\n",
        "<br> <br>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1otbY2IvQ_kzks6OMJvfHi_Zf1Zfvp0Nf\"  alt=\"info\" height=\"20\"/> `BeautifulSoup` does not actually gather information from the web.  We will use the `requests` library for that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDuD_qj9IxLP",
        "colab_type": "text"
      },
      "source": [
        "#Learn to Scrape with Simple Inline HTML\n",
        "\n",
        "Let's start with this simple HTML page given below as a string: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H00yNF3_uuKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simple_html = \"\"\"\n",
        "<html>\n",
        "\n",
        "<head>\n",
        "  <style>\n",
        "    li {font-size: 18px;}\n",
        "  </style\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "  <div style=\"border-style: dotted; padding: 10px\">\n",
        "    <h1>Today's Learning Objectives</h1>\n",
        "    <ul>\n",
        "      <li>Decipher basic HTML</li>\n",
        "      <li>Retrieve information from Internet</li>\n",
        "      <li>Parse web data</li>\n",
        "      <li>Gather and prepare data systematically</li>\n",
        "    </ul>\n",
        "    <br>\n",
        "  </div>\n",
        "</body>\n",
        "\n",
        "</html>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKwJwQiHjmhZ",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/>  **Quick HTML Review**\n",
        "> What tags do we see on this page?  \n",
        "> What attributes?  \n",
        "> What's the inner HTML text of the header?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AqWBqN70t-e",
        "colab_type": "text"
      },
      "source": [
        "Now we will tell Python to render this string as HTML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR7vpgdGvQRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(simple_html)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JbPxSix3MP6",
        "colab_type": "text"
      },
      "source": [
        "This simple \"page\" contains a list of learning objectives for today's workshop. Now we will see how `BeautifulSoup` can extract information from this HTML.\n",
        "\n",
        "First we need to import `BeautifulSoup` and parse the HTML string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NTv9j2G5Omt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxqSZc7UPxbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = bs(simple_html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08WUfmF0QIKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsv1EITAQOqp",
        "colab_type": "text"
      },
      "source": [
        "When we print out `soup`, it looks like `BeautifulSoup` hasn't done anything!  But no worries -- it has indeed parsed our code and `BeautifulSoup` now knows how to navigate through the HTML DOM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7JIsSw3Qgjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(soup)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkjBrNoJLNVc",
        "colab_type": "text"
      },
      "source": [
        "### Find by tag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Tphk26QlYp",
        "colab_type": "text"
      },
      "source": [
        "We begin by using the `find()` method to extract the header of our HTML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y19Bk4CHLPsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find('h1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POZRpITeRWLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(soup.find('h1'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IOnOX64RZTg",
        "colab_type": "text"
      },
      "source": [
        "`find()` returns a tagged element, but we can grab just the inner HTML text instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24AqJmFpRrNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find('h1').text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqkdCh4URrov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(soup.find('h1').text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WliT3c4pR0mj",
        "colab_type": "text"
      },
      "source": [
        "We now have a way to extract text from a webpage -- powerful stuff!  \n",
        "\n",
        "What do you think will be returned if we look for list tags (`li`)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyfRsaFnRrrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find('li')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yp3vUeZSEoC",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1DzGWG2ZiMDuh4f4ZSQJiA85q-rs6FRYl\"  alt=\"warning\" height=\"20\"/> `BeautifulSoup` returns ONLY the FIRST matching element when we use `find()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ75L1fvLP6l",
        "colab_type": "text"
      },
      "source": [
        "###Find all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbOtBcr6Sg0E",
        "colab_type": "text"
      },
      "source": [
        "If we would like `BeautifulSoup` to return ALL matching elements, we can use `find_all()` instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mGMr9VMLUX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find_all('li')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0k6_ZBXTkuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(soup.find_all('li'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHno1ME9Tx-I",
        "colab_type": "text"
      },
      "source": [
        "Using `find_all()` yields a result set containing all of list elements on the \"page.\"  You can basically think of a result set as actinly like a list. \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1DzGWG2ZiMDuh4f4ZSQJiA85q-rs6FRYl\"  alt=\"warning\" height=\"20\"/> `BeautifulSoup` does not allow you to apply `.text` to a result set.  The following code **will fail**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuCGOhboTkxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find_all('li').text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4fu3oHxUhOP",
        "colab_type": "text"
      },
      "source": [
        "Instead, you must apply `.text` to each item in the result set individually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdAvyYN6UWig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for item in soup.find_all('li'):\n",
        "  print(item.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKEltegqUWlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_objectives = [item.text for item in soup.find_all('li')]\n",
        "\n",
        "learning_objectives"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJl4-qR0U_oG",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1b88t_6cp1ozWJydV1CyN2k0ZAyPTZh1V\"  alt=\"tip\" height=\"22\"/>  The two **most common mistakes** I see in web scraping with `BeautifulSoup` are:\n",
        "- Using `find()` when you really want `find_all()`\n",
        "- Attempting to apply `.text` to a result set like the output of `find_all()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZExVtIZMOm4",
        "colab_type": "text"
      },
      "source": [
        "###Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOYU0rktXn5c",
        "colab_type": "text"
      },
      "source": [
        "For the exercises that follow, please use this HTML code describing today's agenda and tools:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBcOBj8lMQV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "workshop_html = \"\"\"\n",
        "<html>\n",
        "\n",
        "<body>\n",
        "  <h1>Today's Workshop</h1>\n",
        "  <div id='agenda' style=\"background-color: aliceblue\">\n",
        "    <h2>Agenda</h2>\n",
        "    <p>Today's workshop is comprised of three main sections:</p>\n",
        "    <ol>\n",
        "      <li>HTML Basics</li>\n",
        "      <li>Scraping Basics</li>\n",
        "      <li>Scraping Pipeline</li>\n",
        "    </ol>\n",
        "  </div>\n",
        "  \n",
        "  <div id='tools' style='background-color: honeydew'>\n",
        "    <h2>Tools</h2>\n",
        "    <p>You will be learning about two primary Python libraries:</p>  \n",
        "    <ol>\n",
        "      <li>BeautifulSoup</li>\n",
        "      <li>requests</li>\n",
        "    </ol>\n",
        "  </div>\n",
        "</body>\n",
        "\n",
        "</html>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3wwCI9NJZPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(workshop_html)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpdrMjBgaQ3i",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/> **Exercise 1 - Finding the header**  _(Solutions to all exercises provide at bottom of notebook.)_\n",
        "> Parse `workshop_html` with `BeautifulSoup`.  Find the main header text (`h1`) and save it in a variable.  Verify that you have the text by checking the `type` of your variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6adKDP0bEKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO9Nh2wUbETs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYpHfOvjbEzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhjw8y_JbNHd",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/> **Exercise 2 - Finding the paragraphs**\n",
        "\n",
        "Now find all the paragraphs in `workshop_html` and print out the text that you find."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKUg-aurb8bM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4Ec96Q_b8eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXuDZ968cTkT",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/> **BONUS: Exercise 3 - Finding the agenda items**\n",
        "\n",
        "Create a list of all of the agenda items for today's workshop.  Be sure to store only the TEXT for the AGENDA items!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUYIOQG0ciZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyvvjM2tcic1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqq1HAHnJZ4b",
        "colab_type": "text"
      },
      "source": [
        "#Scrape Test Webpage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENkQA206dhqK",
        "colab_type": "text"
      },
      "source": [
        "In the last exercise, we found out that oftentimes using only the HTML tags alone won't be granular enough.  \n",
        "\n",
        "Let's work with a more complicated HTML file to see what other options are available.\n",
        "\n",
        "First download this file to your computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQabS3_6uC6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.github.com/kimfetti/Conferences/master/PyCon_2020/pycon_info.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehFDkue9u6p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('pycon_info.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO4K3JWGuaDR",
        "colab_type": "text"
      },
      "source": [
        "Double click on this file to view it in your browser.  Once you have gotten a feel for the structure, read the file in and save as a string. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj5tg_MnnwB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pycon_html = open('pycon_info.html').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q2zzBCYog7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pycon_html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDPP_5ygqW7P",
        "colab_type": "text"
      },
      "source": [
        "Since our HTML is a string, we can parse it with `BeautifulSoup` and begin collecting data.  \n",
        "\n",
        "Let's say we are interested in gathering titles and links of events happening today.  Links can be found by looking for anchor, `a`, tags.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B5Oydm6rIDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = bs(pycon_html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK4gJLPwrVPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find_all('a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HaEHZgVslih",
        "colab_type": "text"
      },
      "source": [
        "Whoa -- there are a lot more links on this page other than today's events!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50z8xhqlLfTL",
        "colab_type": "text"
      },
      "source": [
        "###Find by attribute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8J3lOYFsvdp",
        "colab_type": "text"
      },
      "source": [
        "In order to drill down to just the links we are interested in, notice that today's events are contained within a `div` that has `id=today`.  We can first isolate this `div` by searching for it by its `id`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ljh-i2WLhDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "today_div = soup.find(id='today')\n",
        "\n",
        "today_div"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFX6VVDRtFj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(today_div)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSbVBUzltRIa",
        "colab_type": "text"
      },
      "source": [
        "Now we will look for all of the anchor tags that are contained within this division."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJBi-y4StLqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "today_div.find_all('a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmkC8X_4xnbC",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1b88t_6cp1ozWJydV1CyN2k0ZAyPTZh1V\"  alt=\"tip\" height=\"22\"/>   You can find elements by pretty much any attribute.  Let's find elements with that are members of the `events` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1IBgegQxLgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find_all(class_ = 'events')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFKaUQeczI8S",
        "colab_type": "text"
      },
      "source": [
        "Passing a dictionary of attributes works as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cPgx8kgy4lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find_all(attrs={'class':'events', 'id': 'tomorrow'}) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdtgdj92Lm0S",
        "colab_type": "text"
      },
      "source": [
        "###Retrieve attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ERJqjn_tZsC",
        "colab_type": "text"
      },
      "source": [
        "If we want to just get the names of today's events, we can simply cycle through today's links and collect the `.text`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gjThbpwtLui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "today_text = [link.text for link in today_div.find_all('a')]\n",
        "\n",
        "today_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTnrWzSGxdIN",
        "colab_type": "text"
      },
      "source": [
        "But what would we do if we wanted the **hyperlinks** to each of those events?\n",
        "\n",
        "`BeautifulSoup` allows you to retrieve element attributes.  You will reference these using the same syntax as dictionary key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dqcWf7jLs_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "today_div.find('a')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgSsqg2czq9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "today_div.find('a')['href']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBC1yquizvMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(today_div.find('a')['href'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPvUjoF9zy8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "today_links = [link['href'] for link in today_div.find_all('a')]\n",
        "\n",
        "today_links"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J181BQ3_L0bZ",
        "colab_type": "text"
      },
      "source": [
        "###Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8rfPI2m1bmM",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/> **Exercise 4 - Tomorrow's event tuples** \n",
        "> Create a list of tuples for each of tomorrow's events.  The first element in your tuples will be the event title and the second will be the event link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoiUcz0aL1fJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhvssAMI1Q80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5DAy_WZ08mh",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/> **Exercise 5 - Finding the event headers** \n",
        "> Using `pycon_html` find the header text for today's and tomorrow's events by referencing the `events` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoJ_Rdc91uie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0_lE9si1umo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFqj3GO-1uwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwJEaE82L4tj",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "#Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcxKoYVhkMdm",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/>  **Quick HTML Review**\n",
        "> What tags do we see on this page? <br>\n",
        "`div`, `h1`, `ul` (unordered list), `li` (list item)\n",
        "\n",
        "> What attributes? <br>\n",
        "`style` for the `div` container\n",
        "\n",
        "> What's the inner HTML text of the header? <br>\n",
        "\"Today's Learning Objectives\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhDzJPNQbRDt",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/> **Exercise 1 - Finding the header**\n",
        "\n",
        "> Parse `workshop_html` with `BeautifulSoup`.  Find the main header text (`h1`) and save it in a variable.  Verify that you have the text by checking the `type` of your variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smuIFTdOL6Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = bs(workshop_html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tyg2g3WbUn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "header = soup.find('h1').text\n",
        "\n",
        "print(header)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtB84wARbXZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(header)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni-mQghTcBV9",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/> **Exercise 2 - Finding the paragraphs**\n",
        "\n",
        "Now find all the paragraphs in `workshop_html` and print out the text that you find."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-9PYDY5bYbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup.find_all('p')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By_rc__LcDv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for paragraph in soup.find_all('p'):\n",
        "  print(paragraph.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwdPE0UackhC",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/> **BONUS: Exercise 3 - Finding the agenda items**\n",
        "\n",
        "Create a list of all of the agenda items for today's workshop.  Be sure to store only the TEXT for the AGENDA items!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmfciqaKcIig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agenda_items = [li.text for li in soup.find_all('li')[:3]]\n",
        "\n",
        "print(agenda_items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0mIv8rqcsvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Later we will learn a better way: \n",
        "#  First look for the div that contains the agenda items\n",
        "\n",
        "agenda_div = soup.find('div', id='agenda')\n",
        "\n",
        "agenda_items = [li.text for li in agenda_div.find_all('li')]\n",
        "\n",
        "print(agenda_items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbjUrQeC2W1-",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/> **Exercise 4 - Tomorrow's event tuples** \n",
        "> Create a list of tuples for each of tomorrow's events.  The first element in your tuples will be the event title and the second will be the event link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjbPnuEg2SHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tomorrow_tuples = [(a.text, a['href']) for a in soup.find(id='tomorrow').find_all('a')]\n",
        "\n",
        "tomorrow_tuples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLjUUS601zeY",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=18s6CjUtjr0M24K57uMdtmXvK5TrV34Tv\"  alt=\"exercise\" height=\"20\"/> **Exercise 5 - Finding the event headers** \n",
        "> Using `pycon_html` find the header text for today's and tomorrow's events by referencing the `events` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTYJ7raoc9bG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "event_headers = [div.find('h2') for div in soup.find_all(class_='events')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHNsdYdU2C3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "event_header_text = [header.text for header in event_headers]\n",
        "\n",
        "event_header_text"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}